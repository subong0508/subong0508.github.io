<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Vision</title>
    <description>My personal blog for studying; mainly related to data
</description>
    <link>http://subong0508.github.io/</link>
    <atom:link href="http://subong0508.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 21 Jun 2021 19:06:48 +0900</pubDate>
    <lastBuildDate>Mon, 21 Jun 2021 19:06:48 +0900</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title>Graph Theory with Python</title>
        <description>&lt;h1 id=&quot;section&quot;&gt;서로소 집합&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;시간복잡도: $O(V + M \log_{2}{V})$&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;# 원소가 속한 집합 찾기
def find_parent(parent, x):
    if parent[x] != x:
        parent[x] = find_parent(parent, parent[x])
    return parent[x]

# 두 원소가 속한 집합 merge
def union(parent, a, b):
    a = find_parent(parent, a)
    b = find_parent(parent, b)
    if a &amp;lt; b:
        parent[b] = a
    else:
        parent[a] = b
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;사이클 판별&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;for i in range(num_edges):
    a, b = map(int, input().split())
    if find_parent(parent, a) == find_parent(parent, b):
        cycle = True
        print(&quot;Cycle&quot;)
    else:
        union(parent, a, b)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&quot;minimum-spanning-tree&quot;&gt;크루스칼 알고리즘: Minimum Spanning Tree&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;시간복잡도: $O(E \log {E})$&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;res = 0
edges.sort()
for e in edges:
    cost, a, b = e
    # not cycle
    if find_parent(parent, a) != find_parent(parent, b):
        union(parent, a, b)
        res += cost
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&quot;section-1&quot;&gt;위상 정렬&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;시간복잡도: $O(V + E)$&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;def topological_sort():
    result = []
    q = deque()

    # 진입차수가 0인 노드들 큐에 삽입
    for i in range(1, v+1):
        if indegree[i] == 0:
            q.append(i)

    while q:
        now = q.popleft()
        result.append(now)
        for i in graph[now]:
            indegree[i] -= 1
            # 진입차수가 0이 된다면
            if indegree[i] == 0:
                q.append(i)
    
    return result
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Sun, 28 Feb 2021 00:00:00 +0900</pubDate>
        <link>http://subong0508.github.io/data%20structure/2021/02/28/GraphTheory.html</link>
        <guid isPermaLink="true">http://subong0508.github.io/data%20structure/2021/02/28/GraphTheory.html</guid>
        
        <category>python</category>
        
        <category>data-structure</category>
        
        <category>graph</category>
        
        <category>shortest-path</category>
        
        
        <category>Data structure</category>
        
      </item>
    
      <item>
        <title>Shortest Path with Python</title>
        <description>&lt;p&gt;오늘은 파이썬을 이용해 weighted graph(가중치가 있는 그래프)에서 최단 경로를 찾는 방법을 알아보겠습니다.&lt;/p&gt;

&lt;p&gt;가중치가 없는 그래프라면 &lt;strong&gt;BFS&lt;/strong&gt;를 통해 최단 경로를 손쉽게 구할 수 있습니다.&lt;/p&gt;

&lt;h1 id=&quot;section&quot;&gt;다익스트라 알고리즘&lt;/h1&gt;

&lt;p&gt;다익스트라 알고리즘은 한 노드에서 다른 노드로 가는 각각의 최단 경로를 구해주는 알고리즘입니다.
다익스트라는 기본적으로 그리디 알고리즘의 한 종류로, 방문하지 않은 노드 중 가장 가까운 노드를 통해 갈 수 있는 경로를 개선합니다.&lt;/p&gt;

&lt;p&gt;다익스트라 알고리즘을 사용할 때는 시간복잡도를 개선하기 위해 힙 자료구조를 사용하고, 시간 복잡도는 $O(E \log {V})$가 됩니다.&lt;/p&gt;

&lt;p&gt;파이썬으로 간단하게 구현하면 다음과 같습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;import heapq


# weighted graph
graph = [
    [0, 10, 20],
    [2, 0, 3],
    [10, 4, 0]
]
INF = int(1e9)


def dijkstra(start, graph):
    distance = [INF for _ in range(len(graph))]
    distance[start] = 0
    q = []
    heapq.heappush(q, (0, start)) # 거리, 노드
    while q:
        dist, now = heapq.heappop(q)
        # 이미 처리된 노드
        if distance[now] &amp;lt; dist:
            continue
        for i in range(len(graph)):
            if dist+graph[now][i] &amp;lt; distance[i]:
                distance[i] = dist+graph[now][i]
                heapq.heappush(q, (distance[i], i))
    return distance


print(dijkstra(0, graph)) # 0 10 13
print(dijkstra(1, graph)) # 2 0 3
print(dijkstra(2, graph)) # 6 4 0
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&quot;section-1&quot;&gt;플로이드 워셜 알고리즘&lt;/h1&gt;

&lt;p&gt;다음은 모든 지점에서 다른 모든 지점으로 가는 최단 경로를 구해주는 플로이드 워셜 알고리즘에 대해서 알아보겠습니다.&lt;/p&gt;

&lt;p&gt;플로이드 워셜 알고리즘의 시간복잡도는 $O(V^{3})$이라, 일반적인 코딩 테스트 환경에서는 정점의 수가 1000개 이하인 경우만 가능합니다.&lt;/p&gt;

&lt;p&gt;파이썬으로 구현한 코드는 다음과 같습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;# weighted graph
INF = int(1e9)
graph = [
    [0, 4, INF, 6],
    [3, 0, 7, INF],
    [5, INF, 0, 4],
    [INF, INF, 2, 0]
]
n = len(graph)

for k in range(n):
    for i in range(n):
        for j in range(n):
            graph[i][j] = min(graph[i][j], graph[i][k]+graph[k][j])

print(*graph, sep='\n')
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Sat, 27 Feb 2021 00:00:00 +0900</pubDate>
        <link>http://subong0508.github.io/data%20structure/2021/02/27/ShortestPath.html</link>
        <guid isPermaLink="true">http://subong0508.github.io/data%20structure/2021/02/27/ShortestPath.html</guid>
        
        <category>python</category>
        
        <category>data-structure</category>
        
        <category>graph</category>
        
        <category>shortest-path</category>
        
        
        <category>Data structure</category>
        
      </item>
    
      <item>
        <title>DFS, BFS with Python</title>
        <description>&lt;h1 id=&quot;dfs--&quot;&gt;DFS(깊이 우선 탐색)&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Depth-First Search&lt;/strong&gt;의 약자로, 그래프에서 깊은 부분을 우선적으로 탐색하는 알고리즘이다.&lt;/p&gt;

&lt;p&gt;그래프는 노드(Node)/정점(Vertex)과 간선(Edge)로 구성되는데 그래프를 표현하는 방법으로는 &lt;strong&gt;인접 행렬, 인접 리스트&lt;/strong&gt;가 있다.
인접 행렬은 NxN 행렬을 만들어서 i번째 노드에서 j번째 노드로 갈 수 있다면 1을 표시, 갈 수 없다면 0을 표시하는 것이 일반적이다.
인접 리스트의 i번째 원소는 i번째 노드에서 갈 수 있는 노드들을 담고 있다.&lt;/p&gt;

&lt;p&gt;DFS를 파이썬으로 나타낸 코드는 다음과 같다. 시간복잡도는 인접 리스트로 나타냈을 때 $O(V + E)$에 해당한다. (인접 행렬은 $O(V^{2})$)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;# 인접 리스트
graph = [
    [1, 2],
    [0, 3],
    [0],
    [3]
]
# 방문 여부
visited = [False] * len(graph)
stack = []


def dfs(i, visited, stack):
    stack.append(i)
    visited[i] = True
    for j in graph[i]:
        if not visited[j]:
            dfs(j, visited, stack)


dfs(0, visited, stack)
print(*stack) # 0 1 3 2
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&quot;bfs--&quot;&gt;BFS(너비 우선 탐색)&lt;/h1&gt;

&lt;p&gt;BFS를 수행할 때는 선입선출의 특성을 띠는 큐 자료구조를 사용한다. BFS의 중요한 특징은 한 노드에서 다른 노드로 가는 최단거리를 항상 구한다는 것이다.&lt;/p&gt;

&lt;p&gt;BFS를 파이썬으로 나타낸 코드는 다음과 같다. 시간복잡도는 인접 리스트로 나타냈을 때 $O(V + E)$에 해당한다. (인접 행렬은 $O(V^{2})$)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;from collections import deque


# 인접 리스트
graph = [
    [1, 2],
    [0, 3],
    [0],
    [3]
]
# 방문 여부
visited = [False] * len(graph)
stack = []


def bfs(start, visited, stack):
    q = deque([start])
    while q:
        now = q.popleft()
        visited[now] = True
        stack.append(now)
        for j in graph[now]:
            if not visited[j]:
                q.append(j)
    

bfs(0, visited, stack)
print(*stack) # 0 1 2 3
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Sat, 13 Feb 2021 00:00:00 +0900</pubDate>
        <link>http://subong0508.github.io/data%20structure/2021/02/13/DFS,-BFS.html</link>
        <guid isPermaLink="true">http://subong0508.github.io/data%20structure/2021/02/13/DFS,-BFS.html</guid>
        
        <category>graph</category>
        
        <category>dfs</category>
        
        <category>bfs</category>
        
        <category>python</category>
        
        <category>data-structure</category>
        
        
        <category>Data structure</category>
        
      </item>
    
      <item>
        <title>Heap with Python</title>
        <description>&lt;p&gt;힙이란 우선순위큐(Priority Queue)를 이진 트리로 구현한 자료구조 입니다.
힙의 삽입, 삭제 연산은 $O(\log n)$의 시간복잡도를 가집니다.&lt;/p&gt;

&lt;p&gt;힙은 파이썬 내장모듈인 &lt;code class=&quot;highlighter-rouge&quot;&gt;heapq&lt;/code&gt;를 이용해서 손쉽게 구현할 수 있습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;import heapq

arr = [4, 5, 6, 7, 9, 8, 3, 1, 2]
heapq.heapify(arr)

print(heapq.nsmallest(3, arr)) # 1 2 3
print(heapq.nlargest(3, arr)) # 7 8 9

while arr:
    print(heapq.heappop(arr)) # 1 2 3 4 5 6 7 8 9

data = [5, 4, 6, 3]
for d in data:
    heapq.heappush(arr, d)
    print(arr[0]) # 5 4 4 3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;파이썬의 &lt;code class=&quot;highlighter-rouge&quot;&gt;heapq&lt;/code&gt; 모듈은 최소힙만 지원하므로 최대힙을 구현하기 위해서는 각각의 값들에 -를 붙여서 넣어주고, &lt;code class=&quot;highlighter-rouge&quot;&gt;pop&lt;/code&gt; 연산을 수행할 때 다시 -1을 곱해주는 방법을 사용합니다.&lt;/p&gt;

&lt;p&gt;또한 &lt;strong&gt;Key &amp;amp; Value&lt;/strong&gt; 페어를 통해 힙을 구현할 수도 있습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;keys = [1, 2, 3]
values = ['hello', 'python', 'world']
data = list(zip(keys, values))
h = []
for k, v in data:
    # key, value 순서대로 넣어줌
    heapq.heappush(h, (k, v))

while h:
    k, v = heapq.heappop(h)
    print(&quot;Key: %d, Value: %s&quot; % (k, v)) # Key: 1, Value: hello / Key: 2, Value: python / Key: 3, Value: world /
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Sat, 06 Feb 2021 00:00:00 +0900</pubDate>
        <link>http://subong0508.github.io/data%20structure/2021/02/06/Heap.html</link>
        <guid isPermaLink="true">http://subong0508.github.io/data%20structure/2021/02/06/Heap.html</guid>
        
        <category>sorting</category>
        
        <category>python</category>
        
        <category>data-structure</category>
        
        
        <category>Data structure</category>
        
      </item>
    
      <item>
        <title>정렬 with Python</title>
        <description>&lt;p&gt;이번 포스팅에서는 여러 정렬 기법에 대해 알아보고 파이썬으로 간단하게 구현해보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;selection-sort&quot;&gt;선택 정렬(Selection Sort)&lt;/h2&gt;

&lt;p&gt;선택 정렬은 한마디로 &lt;strong&gt;Priority Queue with Unsorted Array&lt;/strong&gt;라고 할 수 있습니다.
우선순위 큐가 하나 있다고 가정해봅시다. 데이터를 삽입할 때는 항상 끝에 삽입하고,
&lt;code class=&quot;highlighter-rouge&quot;&gt;pop&lt;/code&gt; 연산을 오름차순/내림차순으로 수행합니다. 또한 시간복잡도는 $O(n^2)$ 입니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;array = [7, 5, 9, 0, 3, 1, 6, 2, 4, 8]

for i in range(len(array)):
    min_idx = i
    for j in range(i+1, len(array)):
        if array[j] &amp;lt; array[min_idx]:
            min_idx = j
    # swap
    array[min_idx], array[i] = array[i], array[min_idx]

print(array)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;insertion-sort&quot;&gt;삽입 정렬(Insertion Sort)&lt;/h2&gt;

&lt;p&gt;삽입 정렬은 선택 정렬과 반대로 &lt;strong&gt;Sorted Array&lt;/strong&gt;로 구현된 우선순위 큐입니다. 최악의 경우 시간복잡도는 선택 정렬과 동일하게 $O(n^2)$이지만 이미 정렬된 경우에는 $O(n)$에 가까울 정도로 빠릅니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;array = [7, 5, 9, 0, 3, 1, 6, 2, 4, 8]

for i in range(len(array)-1):
    j = i+1
    while j &amp;gt;= 1 and array[j] &amp;lt; array[j-1]:
        # swap
        array[j-1], array[j] = array[j], array[j-1]
        j -= 1

print(array)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;heap-sort&quot;&gt;힙 정렬(Heap Sort)&lt;/h2&gt;

&lt;p&gt;힙 정렬은 이름과 같이 힙을 이용하여 정렬하는 방법입니다. 시간복잡도는 $O(n\log n)$에 해당합니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;import heapq

array = [7, 5, 9, 0, 3, 1, 6, 2, 4, 8]

def heap_sort(arr):
    q = []
    for a in arr:
        heapq.heappush(q, a)
    arr = []
    while q:
        arr.append(heapq.heappop(q))
    return arr

print(heap_sort(array))
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;quick-sort&quot;&gt;퀵 솔트(Quick Sort)&lt;/h2&gt;

&lt;p&gt;퀵 솔트란 하나의 피봇을 정해서 피봇보다 작은 값들 - 피봇 - 피봇보다 큰 값들 순으로 오도록 하는 알고리즘입니다. 퀵 솔트의 구현에서는 대부분 재귀함수를 사용합니다. 시간 복잡도는 보통 $O(n \log n)$이지만 최악의 경우엔 $O(n^2)$이 되기도 합니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;array = [7, 5, 9, 0, 3, 1, 6, 2, 4, 8]

def quick_sort(array):
    if len(array) &amp;lt;= 1:
        return array

    pivot = array[0]
    array = array[1:]

    left_partition = [x for x in array if x &amp;lt;= pivot]
    right_partition = [x for x in array if x &amp;gt; pivot]

    return quick_sort(left_partition) + [pivot] + quick_sort(right_partition)

print(quick_sort(array))
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;merge-sort&quot;&gt;합병 정렬(Merge Sort)&lt;/h2&gt;

&lt;p&gt;마지막으로 살펴볼 정렬 기법은 합병 정렬입니다. 합병 정렬은 어떤 경우에도 $O(n \log n)$의 성능을 보장하지만 대부분의 경우에 퀵 정렬보다 느리다고 합니다. 또한 합병 정렬은 &lt;strong&gt;Divide and Conquer&lt;/strong&gt;의 대표적인 알고리즘 중 하나입니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;array = [7, 5, 9, 0, 3, 1, 6, 2, 4, 8]

def merge(lst1, lst2):
    n1, n2 = len(lst1), len(lst2)
    i = j = 0
    lst = []
    while i &amp;lt; n1 and j &amp;lt; n2:
        if lst1[i] &amp;lt; lst2[j]:
            lst.append(lst1[i])
            i += 1
        else:
            lst.append(lst2[j])
            j += 1

    while i &amp;lt; n1:
        lst.append(lst1[i])
        i += 1
    
    while j &amp;lt; n2:
        lst.append(lst2[j])
        j += 1

    return lst

def merge_sort(arr):
    if len(arr) &amp;lt;= 1:
        return arr
    mid = len(arr) // 2
    left = merge_sort(arr[:mid])
    right = merge_sort(arr[mid:])
    return merge(left, right)

print(merge_sort(array))
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Tue, 02 Feb 2021 00:00:00 +0900</pubDate>
        <link>http://subong0508.github.io/data%20structure/2021/02/02/Sorting.html</link>
        <guid isPermaLink="true">http://subong0508.github.io/data%20structure/2021/02/02/Sorting.html</guid>
        
        <category>sorting</category>
        
        <category>python</category>
        
        <category>data-structure</category>
        
        
        <category>Data structure</category>
        
      </item>
    
      <item>
        <title>Itertools 정리</title>
        <description>&lt;p&gt;내장 라이브러리인 &lt;code class=&quot;highlighter-rouge&quot;&gt;itertools&lt;/code&gt;를 이용해서 조합, 순열, 중복순열, Cartesian Product 등을 손쉽게 구현할 수 있다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;from itertools import combinations, permutations, combinations_with_replacement, product

data = '123'
l = combinations(data, 2)
for e in l:
    print(*e) # 12 13 23

l = permutations(data, 2)
for e in l:
    print(*e) # 12 13 21 23 31 32

l = combinations_with_replacement(data, 2)
for e in l:
    print(*e) # 11 12 13 22 23 33

l = product(data, repeat=2)
for e in l:
    print(*e) # 11 12 13 21 22 23 31 32 33
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Sat, 30 Jan 2021 00:00:00 +0900</pubDate>
        <link>http://subong0508.github.io/python/2021/01/30/Itertools.html</link>
        <guid isPermaLink="true">http://subong0508.github.io/python/2021/01/30/Itertools.html</guid>
        
        <category>python</category>
        
        <category>coding-test</category>
        
        
        <category>Python</category>
        
      </item>
    
      <item>
        <title>스택, 큐 with Python</title>
        <description>&lt;p&gt;이번 포스팅에서는 스택, 큐에 대한 개념을 알아보고 파이썬으로 간단하게 구현해보겠습니다.&lt;/p&gt;

&lt;h1 id=&quot;section&quot;&gt;스택&lt;/h1&gt;

&lt;p&gt;스택은 &lt;strong&gt;LIFO&lt;/strong&gt;(후입선출)의 특성을 가진 자료구조입니다. 시간복잡도는 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;삽입: $O(1)$&lt;/li&gt;
  &lt;li&gt;삭제: $O(1)$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;파이썬에서는 다른 라이브러리를 쓸 필요없이 기본 자료형인 &lt;code class=&quot;highlighter-rouge&quot;&gt;list&lt;/code&gt;를 활용하여 삽입 및 삭제 연산을 수행할 수 있습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;arr = [1, 2, 3, 4, 5]
stack = []

# 삽입
for a in arr:
    stack.append(a)
print(stack)

# 삭제
while stack:
    print(stack.pop())
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&quot;section-1&quot;&gt;큐&lt;/h1&gt;

&lt;p&gt;큐는 기본적으로 &lt;strong&gt;FIFO&lt;/strong&gt;(선입선출)의 특성을 띄는 자료구조입니다. 시간복잡도는 앞서 설명한 스택과 동일합니다.&lt;/p&gt;

&lt;p&gt;주의해야할 점은 스택과 다르게 파이썬의 기본 자료구조인 &lt;code class=&quot;highlighter-rouge&quot;&gt;list&lt;/code&gt;를 사용해서 &lt;code class=&quot;highlighter-rouge&quot;&gt;pop(0)&lt;/code&gt;을 통해 삭제연산을 수행하면 시간복잡도가 $O(n)$이 된다는 것입니다.&lt;/p&gt;

&lt;p&gt;따라서 &lt;code class=&quot;highlighter-rouge&quot;&gt;list&lt;/code&gt;를 쓰기보다는 파이썬에서는 내장 모듈인 &lt;code class=&quot;highlighter-rouge&quot;&gt;collections&lt;/code&gt;의 &lt;code class=&quot;highlighter-rouge&quot;&gt;deque&lt;/code&gt;을 쓰면 간단하게 구현할 수 있습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;from collections import deque

q = deque()

# 삽입
arr = [1, 2, 3, 4, 5]
for a in arr:
    q.append(a)

# peek
print(q[0])

# pop
# popleft 말고 pop을 쓰면 선입선출
while q:
    print(q.popleft())
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Thu, 28 Jan 2021 00:00:00 +0900</pubDate>
        <link>http://subong0508.github.io/data%20structure/2021/01/28/Stack,-Queue.html</link>
        <guid isPermaLink="true">http://subong0508.github.io/data%20structure/2021/01/28/Stack,-Queue.html</guid>
        
        <category>stack</category>
        
        <category>queue</category>
        
        <category>python</category>
        
        <category>data-structure</category>
        
        
        <category>Data structure</category>
        
      </item>
    
      <item>
        <title>from Variational Inference to VAE</title>
        <description>&lt;p&gt;이번 포스팅에서는 Bayesian의 중요한 토픽인 Variational Inference부터 그와 연관된 Variational Auto-encoder까지 알아보려고 한다.&lt;/p&gt;

&lt;h1 id=&quot;bayesian-framework&quot;&gt;Bayesian Framework&lt;/h1&gt;

&lt;p&gt;먼저, 베이지안의 기본적인 사고방식부터 알고 가자. 빈도론자와 베이지안의 가장 큰 차이점은 우리가 추정하고자하는 parameter를 확률변수로 보냐/아니냐이다. 빈도론자는 고정된 상수라고 보고 베이지안은 어떤 확률분포를 따르는 확률변수라고 생각한다.&lt;/p&gt;

&lt;p&gt;예를 들어, 우리나라 사람들의 키를 수집한 데이터가 있다고 가정하자. 아무래도 우리가 관심있어 하는 parameter는 우리나라 사람들의 평균 키일 것이다. 빈도론자들은 이 평균 키($\mu$라고 하자.)가 고정된 상수(ex: 168cm)라고 가정하고 ML 방식으로 모수를 추정한다. 그에 비해, 베이지안은 $\mu$에 대한 사전 분포를 먼저 정의한 후(이를 prior belief라고 한다.) 주어진 데이터로 부터 사후분포를 추정한다.&lt;/p&gt;

&lt;p&gt;우리나라 사람들의 평균 키가 매우 작다고 믿는 베이지안은 평균이 160cm인 정규분포를 사전분포로 가정할 것이다. 그런데 데이터에 180cm 이상인 사람들이 많다면 데이터를 본 이후 사후분포는 평균이 175cm 정도인 정규분포가 된다. 한편, 빈도론자는 평균 키는 185cm구나!라고 결론을 지을 것이다.&lt;/p&gt;

&lt;p&gt;글이 길어졌는데, 여튼 베이지안의 핵심은 &lt;strong&gt;데이터에 사전믿음을 결합한다는 것&lt;/strong&gt;에 있다.&lt;/p&gt;

&lt;p&gt;우리가 추정하고자 하는 모수를 $\theta$, 데이터를 $x$라고 할 때 결국 &lt;strong&gt;베이지안의 목표는 사전분포 + 데이터로부터 사후분포를 추론하는 것이다.&lt;/strong&gt; 즉, 다음과 같다.&lt;/p&gt;

&lt;p&gt;$p(\theta\vert X) = \frac{\prod_{i=1}^{n}{p(x_{i}\vert\theta)p(\theta)}}{\int {\prod_{i=1}^{n}{p(x_{i}\vert\theta)p(\theta)d\theta}}} \text{ where } x_{i}’s \text{ are i.i.d samples}$&lt;/p&gt;

&lt;p&gt;그럼 이제 본격적으로 베이지안 입장에서 본 머신러닝 모델에 대해서 이야기해보도록 하자. $x$를 features, $y$를 class label/latent vector, $\theta$를 추정할 parameter로 정의하겠다. 그렇다면 우리가 관심있는 분포는 $x$가 given일 때 $y, \theta$의 결합 분포에 해당한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$p(y, \theta \vert x) = p(y \vert \theta, x)p(\theta) \text{ } \because x \perp\theta$&lt;/li&gt;
  &lt;li&gt;$p(\theta \vert X, Y) = \frac{p(Y \vert X, \theta)p(\theta)}{\int p(Y \vert X, \theta)p(\theta)}\text{ where X, Y denote whole training set}$&lt;/li&gt;
  &lt;li&gt;test: $p(y \vert x, X, Y) = \int{ p(y \vert x, \theta)p(\theta \vert X, Y)d\theta}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그러나 바로 여기에서 문제가 생긴다.  $p(\theta \vert X, Y)$를 구하기 위해서는 분모에 있는 적분이 가능해야 하는데, 
$p(y \vert x, \theta)$와 $p(\theta)$가 conjugate하지 않으면 대부분의 경우에서 적분이 어렵다는 것. test시에도 마찬가지.&lt;/p&gt;

&lt;p&gt;(&lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Conjugate_prior&quot;&gt;conjugate prior&lt;/a&gt;&lt;/strong&gt;: conjugacy에 대해서는 자세히 언급하지 않겠지만, 궁금하신 분들은 이 링크를 참조하길 바란다. 대표적인 conjugate distributions은 beta-binom, poission-gamma 등이 있다.)&lt;/p&gt;

&lt;p&gt;여튼, conjugacy가 없다면 posterior distribution(사후분포)을 구하기가 매우 힘들고 빈도론자들 처럼 $\theta$에 대한 point estimation을 할 수 밖에 없다. 이 경우를 Poor Bayes라고도 한다고… test시에도 이러한 point estimation을 통해 얻어진 $\theta_{MP}$를 가지고 $y$에 대한 추론을 하게 된다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\theta_{MP} = argmax_{\theta}p(\theta \vert X, Y) = argmax_{\theta}P(Y \vert X, \theta)p(\theta)$&lt;/li&gt;
  &lt;li&gt;$p(y \vert x, X, Y) \approx p(y \vert x, \theta_{MP})$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;덧붙여서 말하자면, 빈도론자들이 overfitting을 막기 위해 쓰는 regularization 기법(ex: L2-loss)가 사실 이 Poor Bayes와 본질적으로 동등하다.&lt;/p&gt;

&lt;h1 id=&quot;variational-inference&quot;&gt;Variational Inference&lt;/h1&gt;
&lt;h2 id=&quot;main-goal-to-estimate-ptheta-vert-x&quot;&gt;Main Goal: to estimate $p(\theta \vert x)$&lt;/h2&gt;

&lt;p&gt;그러면 conjugacy가 없고, 다시 말해 analytical하게 푸는 것이 불가능한 상황에서 우리는 어떻게 해야할까? 방법은 크게 두 가지로 나뉜다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;variational inference&lt;/strong&gt;: $q(\theta) \approx p(\theta \vert x)$&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;sampling based method&lt;/strong&gt;: $p(x \vert \theta)p(\theta)$로 부터 샘플링하는 방법. MCMC 등이 있으나 시간이 오래 걸린다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;우리는 여기서 첫 번째 방법인 variational inference에 대해 알아보려고 한다. approximate posterior를 가정하고, true posterior과 최대한 가깝게 approximate posterior를 추정하는 방법이다. 분포의 거리를 측정하기 위해 우리는 KL-divergence를 사용한다. KL-divergence는 워낙 유명한 토픽이고 서치하기도 쉬우니까 생략..&lt;/p&gt;

&lt;p&gt;$\hat{q}(\theta) = argmin_{q}D_{KL}(q(\theta) \vert\vert p(\theta \vert x)) = argmin_{q} \int q(\theta)log\frac{q(\theta)}{p(\theta \vert x)}d\theta$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;문제1: $p(\theta \vert x)$를 모른다.&lt;/li&gt;
  &lt;li&gt;문제2: 분포에 대한 optimization은 어떻게 할 수 있나?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Sol)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$logp(x) = E_{q(\theta)}[logp(x)] = \int q(\theta)logp(x)d\theta = \int q(\theta)log\frac{p(x, \theta)}{p(\theta \vert x)}d\theta= \int q(\theta)log\frac{p(x, \theta)}{p(\theta \vert x)}\frac{q(\theta)}{q(\theta)}d\theta$&lt;/p&gt;

&lt;p&gt;$= \int q(\theta) log\frac{p(x, \theta)}{q(\theta)}d\theta + \int q(\theta) log\frac{q(\theta)}{p(\theta \vert x)}d\theta = \mathcal{L}(q(\theta)) + D_{KL}(q(\theta) \vert\vert p(\theta \vert x))$&lt;/p&gt;

&lt;p&gt;따라서, $D_{KL}(q(\theta) \vert\vert p(\theta \vert x))$를 minimize하는 문제는 $\mathcal{L}(q(\theta))$를 maximize하는 문제와 동등해진다.&lt;/p&gt;

&lt;p&gt;$\mathcal{L}(q(\theta)) = \int q(\theta) log\frac{p(x, \theta)}{q(\theta)}d\theta = \int q(\theta) log\frac{p(x \vert \theta)p(\theta)}{q(\theta)}d\theta$&lt;/p&gt;

&lt;p&gt;&lt;b&gt;&lt;font color=&quot;red&quot;&gt;$= E_{q(\theta)}[logp(x \vert \theta)] - D_{KL}(q(\theta) \vert\vert p(\theta)) = \text{data likelihood + KL-regularizer term}$&lt;/font&gt;&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;이제 남은 부분은 $q(\theta)$를 어떻게 최적화하는지인데, 크게 두 가지 방법이 있다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Variational_Bayesian_methods&quot;&gt;mean field approximation&lt;/a&gt;&lt;/strong&gt;: $\theta$끼리 독립일 때 사용하는 방법.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;parametric approximation&lt;/strong&gt;: 대부분의 neural network에서 사용하는 방법. $q(\theta)=q(\theta \vert \lambda)$라고 정의한 후 $\lambda$에 대해서 최적화.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;지금까지 배운 것들을 요약해보자면 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Full Bayesian inference: $p(\theta \vert x)$&lt;/li&gt;
  &lt;li&gt;MP inference: $\theta_{MP} = argmax_{\theta}p(\theta \vert X, Y)$&lt;/li&gt;
  &lt;li&gt;Mean field variational inference:  $p(\theta \vert x) \approx q(\theta) = \prod_{j=1}^{m}q_{j}(\theta_{j})$&lt;/li&gt;
  &lt;li&gt;Parametric variational inference: $p(\theta \vert x) \approx q(\theta) = q(\theta \vert \lambda)$&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;latent-variable-models&quot;&gt;Latent Variable Models&lt;/h1&gt;

&lt;p&gt;그럼 VAE를 배우기 전에 먼저 latent variable models에 대해서 짚고 넘어가자. variational inference에 대해서 신나게 공부하다가 갑자기 잠재변수모델이라니 조금 뜬금없어보이지만 VAE는 잠재변수 모델의 일종이기 때문에 반드시 짚고 넘어가야 한다.&lt;/p&gt;

&lt;p&gt;왜 &lt;strong&gt;잠재변수&lt;/strong&gt;를 학습해야하는가? 이미지 데이터를 예로 들어보자. RGB 채널을 갖는 32x32 짜리 이미지 데이터는 32x32x3 = 3072 차원을 갖는다. 그러나 통상적으로 생각해보았을때, 3072 차원을 통째로 다 feature로 쓰기 보다는 이미지를 결정하는 잠재변수가 있다고 보고 이를 바탕으로 추론을 하는 것이 타당하다.&lt;/p&gt;

&lt;p&gt;예를 들어 MNIST 데이터에서 28x28=784개의 픽셀이 모두 의미있는 값이라고 보기보다는 숫자의 모양을 결정하는 변수(가장자리의 빈 정도, 선의 굽은 모양 등)가 있다고 보는 것이 맞다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/MnistExamples.png/440px-MnistExamples.png&quot; alt=&quot;MNIST&quot; /&gt;&lt;/p&gt;

&lt;p&gt;잠재변수 모델을 설명하는데 가장 흔하게 쓰이는 분포가정이 &lt;strong&gt;Mixture of Gaussians&lt;/strong&gt;이다. 즉, 여러개의 가우시안 분포가 혼합되어 있는 분포로 아래 그림과 같다.앞서 말한 대한민국 평균 키로 설명해보자면, 우리나라 사람들의 키의 분포는 남성/여성/성인/아동 등 여러 분포로 나뉠 수 있다.  (&lt;a href=&quot;https://towardsdatascience.com/gaussian-mixture-models-explained-6986aaf5a95&quot;&gt;이미지 출처&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1200/1*lTv7e4Cdlp738X_WFZyZHA.png&quot; alt=&quot;Mixture of Gaussians&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그럼 $i$번째 표본을 $x_{i}$라고 하고 그 표본이 속한 집단을 $z_{i}$(잠재변수)라고 해보자. 그러면 우리가 가진 데이터의 likelihood는 다음과 같이 나타낼 수 있다.&lt;/p&gt;

&lt;p&gt;$p(X, Z \vert \theta)=\prod_{i=1}^{n}p(x_{i}, z_{i} \vert \theta) = \prod_{i=1}^{n}p(x_{i} \vert z_{i},\theta)p(z_{i} \vert \theta) = \prod_{i=1}^{n}\pi_{z_{i}} \mathcal{N}(x_{i} \vert \mu_{z_{i}}, \sigma_{z_{i}}^{2})$&lt;/p&gt;

&lt;p&gt;여기서 $\pi_{j}=p(z_{i}=j)$로 $j$번째 그룹에 속할 확률을 의미하고 추정해야 할 파라미터는 $\theta = ( \mu_{j}, \sigma_{j}, \pi_{j} )_{j=1}^{K}$를 뜻한다.&lt;/p&gt;

&lt;p&gt;만약 $X, Z$를 모두 안다면 $\hat{\theta} = argmax_{\theta}logP(X, Z \vert \theta)$로 쉽게 추정할 수 있겠지만 &lt;strong&gt;문제는 우리는 Z를 모른다는 것이다. 따라서 우리는 $X$의 log likelihood를 최대화&lt;/strong&gt;하게 되고 목표식은 아래와 같다.&lt;/p&gt;

&lt;p&gt;$logP(X \vert \theta)=\int q(Z)logP(X \vert \theta)dZ=\int q(Z) log \frac{P(X, Z \vert \theta)}{P(Z \vert \theta)} \frac{q(Z)}{q(Z)}dZ = \mathcal{L(q(Z))}+D_{KL}(q(Z) \vert\vert p(Z \vert \theta))$&lt;/p&gt;

&lt;p&gt;항상 KL-divergence는 0 이상이므로 $logP(X \vert \theta)$의 lower-bound는 $\mathcal{L}(q(Z))$가 된다. &lt;strong&gt;이를 Variational lower bound 또는 ELBO라고 칭한다.&lt;/strong&gt; 결국, 우리는 이 하한값을 maximize하는 $q, \theta$를 찾는 것으로 목표를 바꾸게 된다. &lt;font color=&quot;red&quot;&gt;결국, 잠재변수만 추가되었을 뿐 위에서 배운 variational inference와 완전히 똑같은 문제다!&lt;/font&gt;&lt;/p&gt;

&lt;p&gt;이를 푸는 방법으로 &lt;strong&gt;EM 알고리즘&lt;/strong&gt;이 존재한다. EM은 Expectation-Maximization의 약자로, 이름 그대로 Expectation step과 Maximization step이 있다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;E-step: $q(Z)$를 추론하는 과정으로, 이때 $\theta=\theta_{0}$으로 고정된다.&lt;br /&gt;
$q(Z) = argmax_{q}\mathcal{L}(q, \theta_{0}) = argmin_{q}D_{KL}(q(z) \vert\vert p(z \vert \theta))=p(Z \vert X, \theta_{0})$&lt;br /&gt;
자세히 풀어서 설명하자면 다음과 같다. $q(Z)$는 Multinomial 분포임을 기억하자.&lt;br /&gt;
$q(z_{i}=k)=p(z_{i}=k \vert x, \theta) = \frac{p(x_{i} \vert k, \theta)p(z_{i}=k \vert \theta)}{\sum_{l=1}^{K}p(x_{i} \vert l, \theta)p(z_{i}=l \vert \theta)}$&lt;/li&gt;
  &lt;li&gt;M-step: $q(Z)$를 고정시켜놓고 $\theta$를 추론하는 과정이다.&lt;br /&gt;
$\hat{\theta} = argmax_{\theta} \mathcal{L}(q, \theta) = argmax_{\theta} \mathbb{E_{Z}}[logp(X, Z \vert \theta)]=\sum_{i=1}^{n}\sum_{k=1}^{K}q(z_{i}=k)logp(x_{i}, k \vert \theta)$&lt;/li&gt;
  &lt;li&gt;repeat 1, 2 until convergence.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;자, 여기서 드는 의문점이 있다. 위의 상황에서는 $Z$가 categorical variable이니까 단순합으로 E-step에서 $P(Z \vert X, \theta)$를 계산할 수 있다. &lt;strong&gt;하지만 $Z$가 만약 continuous variable이라면? $p(x \vert z, \theta), p(z \vert \theta)$가 conjugate 하지 않다면 intractable 하게 된다!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;continuous latent variable을 학습하는 것은 dimension reduction(차원축소) 또는 &lt;strong&gt;representation learning&lt;/strong&gt;에 해당하고 사실 머신러닝에서 매우매우 중요하면서도 어려운 부분이다. 적분으로 인한 intractable 문제를 VAE에서는 어떻게 해결하는지 다음 섹션에서 알아보겠다.&lt;/p&gt;

&lt;h1 id=&quot;stochastic-variational-inference-and-vae&quot;&gt;Stochastic Variational Inference and VAE&lt;/h1&gt;

&lt;p&gt;우리는 지금까지 Bayesian framework를 이용한 variational inference와 latent variable model에 대해서 배웠다. 실제로 관측되지 않는 잠재변수를 모델링하기 위해 variational inference를 사용($q(Z)$를 추론)해 학습을 진행하는 방법이었다. 하지만 사후분포를 추론할 때 처럼 잠재변수 $Z$가 continuous 하다면 intractability 문제에 직면하게 된다. 앞서 잠깐 언급한 바와 같이 이 문제를 해결하기 위해 여러 sampling 방법들이 고안되었다. 하지만 역시 시간이 많이 걸린다. 또한 Monte Carlo로 추정한 gradient는 분산이 매우 커진다고 한다. &lt;strong&gt;이런 한계점을 극복하기 위해 VAE는 reparameterization trick을 이용하였고, end-to-end learning이 가능해졌다!&lt;/strong&gt;&lt;/p&gt;

&lt;font color=&quot;red&quot;&gt;지금까지와 다르게, VAE는 generative model인 동시에 representaion learning을 학습하는 모델인 것을 기억하자.&lt;/font&gt;
&lt;p&gt;즉, 우리의 목표는 두 가지다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Generation을 제대로 할 것 =&amp;gt; $logP(X)$를 maximize하는 목표&lt;/li&gt;
  &lt;li&gt;Latent variable Z의 분포를 제대로 학습할 것 =&amp;gt; $q(Z \vert X) \approx p(Z \vert X)$&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;먼저, 첫 번째 목표를 이루기 위해 $logP(X)$를 풀어쓰면 다음과 같다. (&lt;a href=&quot;http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture13.pdf&quot;&gt;이미지 출처&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbo6sRJ%2FbtqM4yIGX6T%2FjfBk3Mab5Dx4KFsi8QHeZk%2Fimg.png&quot; alt=&quot;logP(X)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;지금까지와 같이, 맨 마지막 KL-term을 제외한 나머지 것들이 lower bound가 된다. &lt;strong&gt;결국, $logP(X)$를 최대화하는 목표는 lower bound를 최대화하는 목표로 바뀌고 이는 동시에 두 번째 목표까지 이루게 된다!&lt;/strong&gt; lower bound 식은 아래와 같다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;$\mathcal{L}(\theta, \phi; x^{(i)}) = D_{KL}(q(z \vert x^{(i)}) \vert\vert p(z))+\mathbb{E_{q(z \vert x^{(i)})}}[logp(x^{(i)} \vert z)]$&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;앞부분은 prior과 approximate posterior와의 KL term이고, 뒷부분은 decoder probability에 해당한다.&lt;/strong&gt; 대부분 잠재변수 Z의 prior 분포를 $\mathcal{N}[0, 1]$와 같은 다루기 쉬운 분포로 정한다. 그러면 $q(z \vert x)$는 어떻게 정의했을까? VAE original paper에서는 다변량 정규분포로 정의하는데, 다음과 같다.&lt;/p&gt;

&lt;p&gt;$q(z_{i} \vert x_{i}, \phi) = \prod_{j=1}^{d}\mathcal{N}[\mu_{j}(x_{i}), \sigma_{j}^{2}(x_{i})]$&lt;/p&gt;

&lt;p&gt;이때 $\mu_{j}(x_{i}), \sigma_{j}^{2}(x_{i})$는 $x_{i}$가 DNN을 통과한 output에 해당한다. 그래서 구현된 코드를 보면 알겠지만, VAE의 encoder에서는 $\mu_{j}(x_{i}), \sigma_{j}^{2}(x_{i})$를 구한다. 그러면 $p(z), q(z \vert x)$의 KL-divergence를 구할 수 있게 된다. (둘 다 정규분포이므로) &lt;strong&gt;사실 이 term은 approximate posterior가 prior와 너무 달라지지 않게 하는 regularizer 역할을 해준다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;decoder probability에 해당하는 뒷부분을 보면 $q(z \vert x)$에 기반하여 $log(x \vert z)$의 평균을 구해야 한다. 바로 여기서 intractability에 직면한다. 앞서 말했다시피 Monte Carlo 방법으로 평균을 추정하게 되면 gradient의 분산이 매우 커지는 동시에 수렴할 때까지 시간이 오래걸리는 문제가 있다. &lt;strong&gt;게다가 무엇보다도, sampling은 미분가능한 연산이 아니기 때문에 역전파로 학습할 수가 없게 된다.&lt;/strong&gt; VAE의 저자들을 똑똑하게도, &lt;strong&gt;reparameterization trick&lt;/strong&gt;을 이용했다.&lt;/p&gt;

&lt;font color=&quot;red&quot;&gt;$q_{\phi}(z \vert x) \rightarrow g(\epsilon, x)$
&lt;/font&gt;

&lt;p&gt;사실 이 수식이 reparam trick의 전부인데, 처음에는 수식만 보고 읭?했었다. 그런데 회귀분석의 문제로 이해하면 쉬운 문제다.&lt;/p&gt;

&lt;p&gt;간단하게 언급하자면, $y$변수(타겟변수)가 $x$변수(feature)와 linear한 관계에 있다고 가정하고 $y = ax+b+\epsilon$식에서 $a, b$를 푸는 것인데 결국 이는 $p(y \vert x)$를 구하는 태스크가되고 $x$는 given, $a, b$는 constant라고 가정하기 때문에 random factor은 $\epsilon$ ~ $N(0, 1)$에서만 생긴다. 즉, $p(y \vert x)$는 $ax+b$를 평균으로하고 1을 분산으로 하는 정규분포가 된다. 따라서 $a, b$는 MLE 방법으로 closed-form solution이 나오게 된다. 지금까지 설명한 VAE와 개념적으로 상당히 비슷함을 알 수 있다.&lt;/p&gt;

&lt;p&gt;결국 $g(\epsilon, x)$는 본인은 deterministic한 function인데 외부에서 noise $\epsilon$이 들어왔다고 이해하게 되고, 미분이 가능해진다. &lt;strong&gt;end-to-end learning이 가능해지는 것이다!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;마지막으로 VAE의 단점인 blurry generation을 짚고 넘어가려고한다. approximate posterior가 regularizer 역할을 하고, reconstruction loss가 실제 cost에 해당한다고 볼 수 있기 때문에 $logp(x \vert z)$를 높이는 방향으로 학습이 된다. 이는 일종의 Linear Regression(MLE)으로 볼 수 있고, 결국 $x$의 평균과 가까워지게 된다. 따라서 VAE로 생성된 이미지는 보다 흐리다.&lt;/p&gt;

&lt;p&gt;VAE로 학습된 Z를 통해 이미지를 생성한 결과는 다음과 같다. (&lt;a href=&quot;https://arxiv.org/pdf/1312.6114.pdf&quot;&gt;이미지 출처&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;D=2인 Z축에서 매우 smooth하게 변하고 있음을 볼 수 있다.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;이번 포스팅에서는 Bayesian의 중요한 토픽인 Variational Inference부터 그와 연관된 Variational Auto-encoder까지 알아보았다. intractible posterior를 estimate하기 위한 기법 중의 하나가 Variational Inference였고 EM 알고리즘 등을 통해 잠재변수 모델에 활용됨을 알 수 있었다. VAE는 이를 활용한 생성모델+잠재변수 모델로 보다 시각화/설명이 용이하지만 흐린 이미지를 생성한다는 것까지 살펴보았다. 앞으로도 representation learning의 중요성은 더 부각될 것 같다. 열심히 공부해야지..&lt;/p&gt;
</description>
        <pubDate>Tue, 22 Dec 2020 00:00:00 +0900</pubDate>
        <link>http://subong0508.github.io/machine%20learning/2020/12/22/from-Variational-Inference-to-VAE.html</link>
        <guid isPermaLink="true">http://subong0508.github.io/machine%20learning/2020/12/22/from-Variational-Inference-to-VAE.html</guid>
        
        <category>bayesian</category>
        
        <category>deep-learning</category>
        
        <category>variational-inference</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
  </channel>
</rss>
