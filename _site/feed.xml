<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Vision</title>
    <description>My personal blog for studying AI
</description>
    <link>http://subong.github.io//</link>
    <atom:link href="http://subong.github.io//feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 20 Dec 2020 16:49:41 +0900</pubDate>
    <lastBuildDate>Sun, 20 Dec 2020 16:49:41 +0900</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title>DCGAN 리뷰</title>
        <description>&lt;p&gt;이 포스팅에서 리뷰할 DCGAN은 사실 GAN을 더욱 더 유명하게 만들어준 논문으로, 이 논문이 publish된 이후로 대부분의 GAN 아키텍쳐는 DCGAN의 아키텍쳐를 따른다.&lt;/p&gt;

&lt;p&gt;기존 CNN을 이용한 DNN에 architectural contraints를 더해줌으로써 hierarchical representation을 학습할 수 있는 것이 이 논문의 주요 내용이다.&lt;/p&gt;

&lt;p&gt;먼저, unsupervised learning의 의의를 설명해보자면 labeled dataset은 구하기 어려운 것에 비해 unlabeled dataset은 구하기가 매우 쉽다. 따라서 구하기 쉬운 대용량의 unlabeled dataset을 이용해 reusable한 feature representation을 학습할 수 있다면 supervised learning에도 유용히 쓰일 수 있고, 우리의 데이터의 분포를 이해할 수 있다.&lt;/p&gt;

&lt;p&gt;이 논문의 proposal은 아래와 같다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;CNN을 이용한 GAN에 여러 constraints를 더 해줌으로써 GAN의 unstability 해결&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;학습된 discriminator를 이미지 분류 문제에 적용했더니 좋은 성능을 보임&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;GAN의 필터를 시각화함으로써 explainability 확장&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;generator는 Word2vec처럼 흥미로운 vector arithmetic 성질이 존재&lt;/strong&gt; ex) king+woman =&amp;gt; queen&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그렇다면 해당 논문의 핵심이라고 할 수 있는 architectural constraints는 무엇일까? 사실 나는 굉장히 대단할 거라고 생각했는데 생각보다 간단해서 놀랐다..&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../../../img/dcgan/1.png&quot; alt=&quot;architectural constraints&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;strided convolution: 이미지 본연의 spatial upsampling을 학습한다.&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;FC layer 대신 feature map을 flatten해서 사용&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Batch Normalization: mode collapsing 방지&lt;/strong&gt; (단, generator output layer와 discriminator input layer에는 적용하지 않음)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;결과적으로는 아래와 같은 구조가 된다.
&lt;img src=&quot;../../../../img/dcgan/dcgan.png&quot; alt=&quot;dcgan&quot; /&gt;&lt;/p&gt;

&lt;p&gt;100-dimension의 uniform distribution을 따르는 랜덤 벡터 Z를 4차원텐서(N x C x H x W)로 reshape 해준 다음 Transpose Convolution을 이용해서 계속 upsampling 해주고, 마지막엔 기본 RGB 이미지처럼 64x64x3으로 바꿔준다.&lt;/p&gt;

&lt;p&gt;이후론 학습에 사용된 여러 테크닉들이 나오는데, 대부분 generator가 학습 데이터를 그냥 외워버리는 것을 방지하거나/아님을 증명하기 위한 것들이다.&lt;/p&gt;

&lt;p&gt;작은 학습률(0.0002) + minibatch SGD를 이용하여 1 epoch 동안 학습을 진행했는데 성과가 좋았다는 것과 5 epoch 이후 오히려 underfitting이 일어났다는 것이 generator가 제대로 학습하고 있다는 증거에 해당한다.&lt;/p&gt;

&lt;p&gt;또한 개인적으로 인상깊었던 것은 duplication을 방지하기 위해 de-noising autoencoder를 이용해 이미지를 코드화한후 비슷한 코드끼리 제거했다는 것(semantic-hashing)이다.&lt;/p&gt;

&lt;p&gt;다음 섹션에서는 실제 데이터에 적용한 emprical validation을 열거한다. 앞서 말한 image classification task를 위해 discriminator의 모든 feature map을 사용하여 CIFAR-10을 분류한 결과 82.8%의 정확도를 달성했다고 한다.&lt;/p&gt;

&lt;p&gt;마지막 섹션에서는 generator가 학습한 representation의 validity를 입증한다. Z의 grid를 나눠서 이미지를 생성해보기도하고, discriminator의 필터를 시각화해보기도 하는데 제일 재미있었던 것은 특정 사물은 잊도록(forgetting) 해보는 실험이었다. 150개의 학습 데이터중 52개의 이미지에서 창문에 대한 bounding box를 수동으로 라벨링하고 generator의 마지막에서 두번째 convolution layer를 이용해 창문이 있는지/없는지 로지스틱 회귀를 fit한다. 이때 기준은 바운딩 박스안의 activation 값이 positive, 랜덤 이미지에서는 negative 값을 가지는지 여부로 정했다고 한다.&lt;/p&gt;

&lt;p&gt;이 모델을 이용해서 회귀계수 값이 0보다 큰 feature map은 drop한 후(random new samples로 대체)  generation을 진행한 결과는 다음과 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../../../img/dcgan/4.png&quot; alt=&quot;windows&quot; /&gt;&lt;/p&gt;

&lt;p&gt;사실 DCGAN 하면 제일 유명한 것 vector arthimetic properties에 관한 것일텐데.. 너무 유명하니까 생략하겠음..&lt;/p&gt;

&lt;p&gt;마지막으로는 future work에 대해 설명하는데, 학습을 오래 시킬수록 오히려 oscillating mode가 생긴다고 한다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;reference: &lt;a href=&quot;https://arxiv.org/pdf/1511.06434.pdf&quot;&gt;Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 20 Dec 2020 00:00:00 +0900</pubDate>
        <link>http://subong.github.io//review/2020/12/20/DCGAN.html</link>
        <guid isPermaLink="true">http://subong.github.io//review/2020/12/20/DCGAN.html</guid>
        
        <category>DCGAN</category>
        
        <category>GAN</category>
        
        <category>deeplearning</category>
        
        <category>generativemodel</category>
        
        
        <category>review</category>
        
      </item>
    
      <item>
        <title>GAN 리뷰</title>
        <description>&lt;p&gt;오늘 리뷰할 논문은 GAN으로 더 잘 알려진, 적대적 인공신경망을 처음으로 제안한 논문이다.&lt;/p&gt;

&lt;p&gt;뭐 이미 말할 필요도 없이 유명하기도 하고, 수많은 variation이 나오기도 했다.&lt;/p&gt;

&lt;p&gt;논문의 제 1저자인 이안 굿펠로우는 GAN의 &lt;strong&gt;generator를 지폐위조범으로, discriminator를&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;경찰로 묘사했다.&lt;/strong&gt; 지폐위조범은 위조 지폐를 더욱 더 진짜 같이 위조하고, 경찰은 그걸 구분하려고&lt;/p&gt;

&lt;p&gt;경쟁하는 과정에서 상호발전이 일어난다는 것이다. 사실 우리의 목표는 경찰보다는&lt;/p&gt;

&lt;p&gt;지폐위조범의 생성능력을 상승시키는 것에 있다. 결국 학습의 끝에서는 경찰이&lt;/p&gt;

&lt;p&gt;어느 것이 위조 지폐인지 진짜 지폐인지 알아볼 수 없도록 말이다.&lt;/p&gt;

&lt;p&gt;이렇듯 기본적인 아이디어는 굉장히 직관적이지만, 이론적 배경은 꽤나 탄탄하다.&lt;/p&gt;

&lt;p&gt;이제 차근차근 하나씩 알아보겠다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;GAN을 알아보기 전, VAE에 대해서 먼저 잠깐 짚고 넘어가자.&lt;/p&gt;

&lt;p&gt;VAE의 가장 큰 문제점은 blurry한 이미지가 생성된다는 것이다. &lt;/p&gt;

&lt;p&gt;여러가지 설명이 있을 수 있겠지만, 필자가 생각하기로는 VAE의 loss function에서&lt;/p&gt;

&lt;p&gt;기인한다고 생각한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdC2FQH%2FbtqNQ4vjwsv%2F1j5oUsSiBtmeek9MJyFld0%2Fimg.png&quot; alt=&quot;gan1&quot; /&gt;
첫 번째 term은 $q_{\phi}(z|x)$가 prior $p_{\theta}(z)$와 너무 달라지지 않게&lt;/p&gt;

&lt;p&gt;조절하는 regularization term이고 두 번째 term은 latent factor $z$로 부터 원래의 데이터&lt;/p&gt;

&lt;p&gt;$x$를 복원하는데서 생기는 loss에 해당한다. 사실 두 번째 term은 회귀분석의 식과&lt;/p&gt;

&lt;p&gt;정확히 일치한다. &lt;/p&gt;

&lt;p&gt;$y = X\beta + \epsilon$라는 가정에서 출발한다. 이때 입실론은 평균이 0, 표준편차가 $\sigma$인&lt;/p&gt;

&lt;p&gt;정규분포를 따른다. 우리는 $x_{i}^{T}\beta$와 $y_{i}$의 오차를 줄여주고 싶기 때문에&lt;/p&gt;

&lt;p&gt;최적화된 파라미터는 다음 수식을 만족한다.&lt;/p&gt;

&lt;p&gt;$\hat{\beta} = argmin_{\beta} {(y-X\beta)^{2}}$&lt;/p&gt;

&lt;p&gt;$\epsilon$이 정규분포를 따르기 때문에 $y$도 정규분포를 따르게 된다. &lt;/p&gt;

&lt;p&gt;이때 Maximum Likelihood 방식으로 $\beta$를&lt;/p&gt;

&lt;p&gt;구하게 되면 다음과 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FmWYVM%2FbtqNXcSuqdE%2FswLTtUUB9N07G2T5XguLTk%2Fimg.png&quot; alt=&quot;gan2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;결국 LSE로 구한 방법과 MLE로 구한 방법이 같아지고, 이는 앞에서 본 VAE의 손실 함수에서 &lt;/p&gt;

&lt;p&gt;두 번째 term에 해당한다. L2 loss를 줄이기 위해서 linear regression은 target의&lt;/p&gt;

&lt;p&gt;평균으로 예측하는 경향이 있기 때문에 VAE로 생성된 함수는 흐려지는 것이다.&lt;/p&gt;

&lt;p&gt;그에 비해 GAN으로 생성하는 이미지는 굉장히 sharp하다. 그럼 이제 수식을 하나하나&lt;/p&gt;

&lt;p&gt;알아보도록 하겠다.&lt;/p&gt;

&lt;h4 id=&quot;objective-function&quot;&gt;&lt;strong&gt;0. Objective Function&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbntm3f%2FbtqNWf90y5I%2FOvcqH8TKxXhE6iRkZUqcx1%2Fimg.png&quot; alt=&quot;gan3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;GAN을 학습하는 과정은 결국 이 minimax 문제를 푸는 것이라 할 수 있다.&lt;/p&gt;

&lt;p&gt;D 입장에서는 진짜 데이터일때(첫 번째 term) 진짜라고 예측할 확률을 극대화(1)하고,&lt;/p&gt;

&lt;p&gt;G가 생성한 가짜 데이터일때(두 번째 term) 진짜라고 예측할 확률을 극소화(0)하여&lt;/p&gt;

&lt;p&gt;objective function 값이 커져야 한다.&lt;/p&gt;

&lt;p&gt;G 입장에서는 D가 생성한 데이터를 진짜로 판별할 확률 $D(G(z))$을 극대화하여&lt;/p&gt;

&lt;p&gt;$log(1-D(G(z)))$를 극소화해야하기 때문에 objective function 값이 작아져야 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FBm36b%2FbtqNSz2GHJf%2FSvrhWlVQ2ceHznrQyH7sBK%2Fimg.png&quot; alt=&quot;gan4&quot; /&gt;&lt;/p&gt;

&lt;p&gt;하지만 이렇게 gradient descent/ascent 방법을 적용하면 문제가 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcLsGsH%2FbtqNU1kj5yP%2Fo6AKAZXSB2TgaPmIO7yS3K%2Fimg.png&quot; alt=&quot;gan5&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 그래프를 보면, G가 제대로 못하는 상황에서 gradient가 작고 잘하는 상황에서&lt;/p&gt;

&lt;p&gt;gradient가 크기 때문에 학습이 원활히 이루어지지 않음을 알 수 있다.&lt;/p&gt;

&lt;p&gt;따라서 실제로 학습을 할 때는&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F54zAz%2FbtqNSzIpyr0%2FUGgURhuNBnLmBtLRobUVP0%2Fimg.png&quot; alt=&quot;gan6&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이런 식으로 바꾼 다음 gradient를 적용한다고 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FAoBWA%2FbtqNQ3pHTln%2FdWKNWEgJW2z7kfAxqVlCU1%2Fimg.png&quot; alt=&quot;gan7&quot; /&gt;&lt;/p&gt;

&lt;p&gt;(a)에서는 generator가 제대로 mapping을 못하고 있고, D도 given G에 대해서 optimal하지 않다.&lt;/p&gt;

&lt;p&gt;(b) D goes to optimum for given G&lt;/p&gt;

&lt;p&gt;(c) G converges to data distribution&lt;/p&gt;

&lt;p&gt;(d) global optimum에 도달. G는 데이터의 분포를 완벽히 학습했고 D는 그냥 찍기가&lt;/p&gt;

&lt;p&gt;되어버렸다.&lt;/p&gt;

&lt;p&gt;그렇다면 실제로 이렇게 학습이 되는지 수식적으로 살펴보도록 하겠다.&lt;/p&gt;

&lt;h4 id=&quot;global-optimality&quot;&gt;&lt;strong&gt;1. Global Optimality&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbaLAsU%2FbtqNXFfQ6ZY%2FXkzGoxm7OfaztMhnMUVoc1%2Fimg.png&quot; alt=&quot;gan8&quot; /&gt;&lt;/p&gt;

&lt;p&gt;먼저, G가 주어졌을 때 D의 optimum은 (2)와 같다는 주장이다. LaTex로 옮기기&lt;/p&gt;

&lt;p&gt;귀찮아서.. 내가 쓴 풀이과정은 아래와 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbaLAsU%2FbtqNXFfQ6ZY%2FXkzGoxm7OfaztMhnMUVoc1%2Fimg.png&quot; alt=&quot;gan9&quot; /&gt;&lt;/p&gt;

&lt;p&gt;사실 인테그랄을 빼고 뭐 합치고 이런 과정에서 뇌피셜이 꽤나 들어가서.. 정확한 풀이인지는&lt;/p&gt;

&lt;p&gt;모르겠지만 대략 위처럼 구할 수 있다.&lt;/p&gt;

&lt;p&gt;그러면 이제 optimal D에 도달했다고 하고 G에 대해서 최적화를 해보자.&lt;/p&gt;

&lt;p&gt;위의 식을 $C(G)$로 바꾸고, $C(G)$를 minimize하는 G가 존재하는지,&lt;/p&gt;

&lt;p&gt;그렇다면 그 G는 어떤 G인지 알아보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fdui0ug%2FbtqNXcLMxOt%2F2sF6Co6Mofs27H7H09M9rK%2Fimg.png&quot; alt=&quot;gan10&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 식을 하나하나 풀면 아래와 같다. 사실은 그냥 $log(4)$를 더하고 뺀 트릭일 뿐…&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FlHfWy%2FbtqNVSAsVw4%2FLvrrghgHv18siuc7heOm5K%2Fimg.png&quot; alt=&quot;gan11&quot; /&gt;&lt;/p&gt;

&lt;p&gt;결국, $p_{g} = p_{d}$를 만족하는 G가 optimal G가 되고 이때 optimum value는&lt;/p&gt;

&lt;p&gt;$-log(4)$에 해당한다.&lt;/p&gt;

&lt;p&gt;최적의 값이 존재한다는 것과 알고리즘으로 값을 찾을 수 있다는 다른 문제기 때문에,&lt;/p&gt;

&lt;p&gt;이제 algorithm에 대한 convergence를 증명해야 한다. 이 문제는 매우 간단하게 증명된다.&lt;/p&gt;

&lt;h4 id=&quot;convergence-of-algorithm&quot;&gt;&lt;strong&gt;2. Convergence of Algorithm&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FciHjBM%2FbtqNWhtdOnC%2F6j5zq54L0WsdauSCAHRmm0%2Fimg.png&quot; alt=&quot;gan12&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 식을 $p_{g}$에 대해서 미분하면 $log(1-D_{G}^{*}(x))$만 남기 때문에 $p_{g}$에 대해서&lt;/p&gt;

&lt;p&gt;convex하고, gradient descent에 의해 $p_{g}$는 $p_{data}$로 수렴한다.&lt;/p&gt;

&lt;p&gt;지금까지 GAN의 이론적 근거에 대해서 알아보았다.&lt;/p&gt;

&lt;p&gt;요약하자면&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;1) given G에 대해서 D의 optimum D* 존재, D가 수렴(1차 미분으로 풀 수 있음)&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;2) D*에 대해서 G가 수렴: $p_{g}$가 $p_{d}$를 만족할 때 까지..&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;3) repeat 1), 2) until converged&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;다음은 GAN으로 생성된 이미지들이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FsSTDc%2FbtqNVSf9gDE%2FuEeuJkhCrrxKhzSR0F8cj1%2Fimg.png&quot; alt=&quot;gan13&quot; /&gt;&lt;/p&gt;

&lt;p&gt;중간중간 부자연스러운 것들도 보이지만, 대체로 학습이 잘되었다.&lt;/p&gt;

&lt;p&gt;그렇다면 GAN은 항상 완벽한 generation을 할 수 있을까? 그건 아니다.&lt;/p&gt;

&lt;p&gt;대표적으로 다음과 같은 문제들이 존재한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;minimax 학습으로 인한 학습의 불안정성, mode collapsing&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;함수 공간을 neural network로 정의하면 함수 공간이 아닌 parameter space가 되기 때문에 가정이 깨짐&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;첫 번째에 대해서 알아보자면, neural network 입장에서는 이게 minimax인지 maxmini인지&lt;/p&gt;

&lt;p&gt;알 길이 없다. 따라서 D가 최적화되지 않은 상태에서 G를 최적화하게 되면&lt;/p&gt;

&lt;p&gt;G는 D가 제일 헷갈리는 샘플만 내놓으면 된다. 또한 data distribution이 여러 개의&lt;/p&gt;

&lt;p&gt;mode가 있을 때(예를 들어, MNIST에서는 숫자 1-10이 이에 해당한다)&lt;/p&gt;

&lt;p&gt;G 입장에서는 1만 완벽하게 생성해도 D가 헷갈리기 때문에 학습이 완료된다.&lt;/p&gt;

&lt;p&gt;(물론 이때 D는 다른 숫자들에 대해서 판별능력이 구리다)&lt;/p&gt;

&lt;p&gt;사실 GAN의 불안정한 학습을 해결하기 위해 여러 방법들이 고안되었고,&lt;/p&gt;

&lt;p&gt;지금도 이에 대해서 활발히 연구가 진행되고 있다고 한다.&lt;/p&gt;

&lt;p&gt;given G에 대해서 D를 optimize하는 것이 만만치 않기 때문에 그렇다.&lt;/p&gt;

&lt;p&gt;두 번째는 보다 일반적인 얘기이다. 위의 모든 증명들은 함수 공간에서 성립하는&lt;/p&gt;

&lt;p&gt;증명인데, 사실 우리는 FC layer, Convolution layer 등 네트워크를 설계하고&lt;/p&gt;

&lt;p&gt;parameter를 최적화한다. 물론 인공신경망이 universal function approximator라는 것은&lt;/p&gt;

&lt;p&gt;잘 알려져 있지만, 우리가 설계한 네트워크가 $f$에 맞을지는 모르는 일..&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;reference: &lt;a href=&quot;https://papers.nips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf&quot;&gt;GAN paper,&lt;/a&gt; &lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/part-i.html&quot;&gt;jaejunyoo.blogspot.com/2019/05/part-i.html&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 19 Dec 2020 00:00:00 +0900</pubDate>
        <link>http://subong.github.io//review/2020/12/19/GAN.html</link>
        <guid isPermaLink="true">http://subong.github.io//review/2020/12/19/GAN.html</guid>
        
        <category>GAN</category>
        
        <category>deeplearning</category>
        
        <category>generativemodel</category>
        
        
        <category>review</category>
        
      </item>
    
      <item>
        <title>Welcome to Jekyll!</title>
        <description>&lt;p&gt;You’ll find this post in your &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run &lt;code class=&quot;highlighter-rouge&quot;&gt;jekyll serve&lt;/code&gt;, which launches a web server and auto-regenerates your site when a file is updated.&lt;/p&gt;

&lt;h2 id=&quot;adding-new-posts&quot;&gt;Adding New Posts&lt;/h2&gt;

&lt;p&gt;To add new posts, simply add a file in the &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory that follows the convention &lt;code class=&quot;highlighter-rouge&quot;&gt;YYYY-MM-DD-name-of-post.ext&lt;/code&gt; and includes the necessary front matter. Take a look at the source for this post to get an idea about how it works.&lt;/p&gt;

&lt;h3 id=&quot;tags-and-categories&quot;&gt;Tags and Categories&lt;/h3&gt;

&lt;p&gt;If you list one or more categories or tags in the front matter of your post, they will be included with the post on the page as links. Clicking the link will bring you to an auto-generated archive page for the category or tag, created using the &lt;a href=&quot;https://github.com/jekyll/jekyll-archives&quot;&gt;jekyll-archive&lt;/a&gt; gem.&lt;/p&gt;

&lt;h3 id=&quot;cover-images&quot;&gt;Cover Images&lt;/h3&gt;

&lt;p&gt;To add a cover image to your post, set the “cover” property in the front matter with the relative URL of the image (i.e. &lt;code&gt;cover: &quot;/assets/cover_image.jpg&quot;&lt;/code&gt;).&lt;/p&gt;

&lt;h3 id=&quot;code-snippets&quot;&gt;Code Snippets&lt;/h3&gt;

&lt;p&gt;You can use &lt;a href=&quot;https://highlightjs.org/&quot;&gt;highlight.js&lt;/a&gt; to add syntax highlight code snippets:&lt;/p&gt;

&lt;p&gt;Use the &lt;a href=&quot;https://github.com/Shopify/liquid/wiki/Liquid-for-Designers&quot;&gt;Liquid&lt;/a&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;highlight&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;&amp;lt;language&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt; tag to add syntax highlighting to code snippets.&lt;/p&gt;

&lt;p&gt;For instance, this template…&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-html&quot; data-lang=&quot;html&quot;&gt;{% highlight javascript %}    
function demo(string, times) {    
  for (var i = 0; i &lt;span class=&quot;nt&quot;&gt;&amp;lt; times&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;++)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;    
    &lt;span class=&quot;na&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;);&lt;/span&gt;    
  &lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;    
&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;    
&lt;span class=&quot;na&quot;&gt;demo&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;(&quot;&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hello&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;world&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;!&quot;,&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{%&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;endhighlight&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;%}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;…will come out looking like this:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span class=&quot;kd&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;demo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;times&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;times&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;demo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;hello, world!&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Syntax highlighting is done using &lt;a href=&quot;https://highlightjs.org/&quot;&gt;highlight.js&lt;/a&gt;. You can change the active theme in &lt;a href=&quot;https://github.com/bencentra/centrarium/blob/2dcd73d09e104c3798202b0e14c1db9fa6e77bc7/_includes/head.html#L15&quot;&gt;head.html&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;images&quot;&gt;Images&lt;/h3&gt;

&lt;p&gt;Lightbox has been enabled for images. To create the link that’ll launch the lightbox, add &lt;code&gt;data-lightbox&lt;/code&gt; and &lt;code&gt;data-title&lt;/code&gt; attributes to an &lt;code&gt;&amp;lt;a&amp;gt;&lt;/code&gt; tag around your &lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt; tag. The result is:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;//bencentra.com/assets/images/falcon9_large.jpg&quot; data-lightbox=&quot;falcon9-large&quot; data-title=&quot;Check out the Falcon 9 from SpaceX&quot;&gt;
  &lt;img src=&quot;//bencentra.com/assets/images/falcon9_small.jpg&quot; title=&quot;Check out the Falcon 9 from SpaceX&quot; /&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;For more information, check out the &lt;a href=&quot;http://lokeshdhakar.com/projects/lightbox2/&quot;&gt;Lightbox&lt;/a&gt; website.&lt;/p&gt;

&lt;p&gt;Check out the &lt;a href=&quot;http://jekyllrb.com&quot;&gt;Jekyll docs&lt;/a&gt; for more info on how to get the most out of Jekyll. File all bugs/feature requests at &lt;a href=&quot;https://github.com/jekyll/jekyll&quot;&gt;Jekyll’s GitHub repo&lt;/a&gt;. If you have questions, you can ask them on &lt;a href=&quot;https://github.com/jekyll/jekyll-help&quot;&gt;Jekyll’s dedicated Help repository&lt;/a&gt;.&lt;/p&gt;

</description>
        <pubDate>Sat, 18 Apr 2015 17:43:59 +0900</pubDate>
        <link>http://subong.github.io//jekyll/2015/04/18/welcome-to-jekyll.html</link>
        <guid isPermaLink="true">http://subong.github.io//jekyll/2015/04/18/welcome-to-jekyll.html</guid>
        
        <category>jekyll</category>
        
        <category>welcome</category>
        
        
        <category>Jekyll</category>
        
      </item>
    
  </channel>
</rss>
